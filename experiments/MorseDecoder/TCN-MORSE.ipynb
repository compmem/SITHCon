{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:52:20.948972Z",
     "start_time": "2021-05-05T14:52:20.939893Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T14:52:21.169340Z",
     "start_time": "2021-05-05T14:52:21.161864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'>\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "sn.set_context(\"poster\")\n",
    "\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "ttype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "ctype = torch.cuda.LongTensor if torch.cuda.is_available() else torch.LongTensor\n",
    "print(ttype)\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import gridspec\n",
    "from deepsith import DeepSITH\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import itertools\n",
    "from csv import DictWriter\n",
    "import os \n",
    "from os.path import join\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from math import factorial\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T18:44:54.861716Z",
     "start_time": "2021-05-04T18:44:54.857876Z"
    }
   },
   "outputs": [],
   "source": [
    "MORSE_CODE_DICT = { 'A':'.-', 'B':'-...', \n",
    "                    'C':'-.-.', 'D':'-..', 'E':'.', \n",
    "                    'F':'..-.', 'G':'--.', 'H':'....', \n",
    "                    'I':'..', 'J':'.---', 'K':'-.-', \n",
    "                    'L':'.-..', 'M':'--', 'N':'-.', \n",
    "                    'O':'---', 'P':'.--.', 'Q':'--.-', \n",
    "                    'R':'.-.', 'S':'...', 'T':'-', \n",
    "                    'U':'..-', 'V':'...-', 'W':'.--', \n",
    "                    'X':'-..-', 'Y':'-.--', 'Z':'--..', \n",
    "                    '1':'.----', '2':'..---', '3':'...--', \n",
    "                    '4':'....-', '5':'.....', '6':'-....', \n",
    "                    '7':'--...', '8':'---..', '9':'----.', \n",
    "                    '0':'-----', ', ':'--..--', '.':'.-.-.-', \n",
    "                    '?':'..--..', '/':'-..-.', '-':'-....-', \n",
    "                    '(':'-.--.', ')':'-.--.-'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T18:44:55.050963Z",
     "start_time": "2021-05-04T18:44:55.025184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..--.. 1010111011101010\n",
      "43\n",
      "[1 0 1 1 1 0 0 0] A\n",
      "[1 1 1 0 1 0 1 0 1 0 0 0] B\n",
      "[1 1 1 0 1 0 1 1 1 0 1 0 0 0] C\n",
      "[1 1 1 0 1 0 1 0 0 0] D\n",
      "[1 0 0 0] E\n",
      "[1 0 1 0 1 1 1 0 1 0 0 0] F\n",
      "[1 1 1 0 1 1 1 0 1 0 0 0] G\n",
      "[1 0 1 0 1 0 1 0 0 0] H\n",
      "[1 0 1 0 0 0] I\n",
      "[1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0] J\n",
      "[1 1 1 0 1 0 1 1 1 0 0 0] K\n",
      "[1 0 1 1 1 0 1 0 1 0 0 0] L\n",
      "[1 1 1 0 1 1 1 0 0 0] M\n",
      "[1 1 1 0 1 0 0 0] N\n",
      "[1 1 1 0 1 1 1 0 1 1 1 0 0 0] O\n",
      "[1 0 1 1 1 0 1 1 1 0 1 0 0 0] P\n",
      "[1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 0] Q\n",
      "[1 0 1 1 1 0 1 0 0 0] R\n",
      "[1 0 1 0 1 0 0 0] S\n",
      "[1 1 1 0 0 0] T\n",
      "[1 0 1 0 1 1 1 0 0 0] U\n",
      "[1 0 1 0 1 0 1 1 1 0 0 0] V\n",
      "[1 0 1 1 1 0 1 1 1 0 0 0] W\n",
      "[1 1 1 0 1 0 1 0 1 1 1 0 0 0] X\n",
      "[1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0] Y\n",
      "[1 1 1 0 1 1 1 0 1 0 1 0 0 0] Z\n",
      "[1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0] 1\n",
      "[1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0] 2\n",
      "[1 0 1 0 1 0 1 1 1 0 1 1 1 0 0 0] 3\n",
      "[1 0 1 0 1 0 1 0 1 1 1 0 0 0] 4\n",
      "[1 0 1 0 1 0 1 0 1 0 0 0] 5\n",
      "[1 1 1 0 1 0 1 0 1 0 1 0 0 0] 6\n",
      "[1 1 1 0 1 1 1 0 1 0 1 0 1 0 0 0] 7\n",
      "[1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0] 8\n",
      "[1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 0] 9\n",
      "[1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0] 0\n",
      "[1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 0 0] , \n",
      "[1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 0 0 0] .\n",
      "[1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0] ?\n",
      "[1 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0] /\n",
      "[1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0] -\n",
      "[1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 0] (\n",
      "[1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 0] )\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "print(MORSE_CODE_DICT['?'], MORSE_CODE_DICT['?'].replace('.', '10').replace('-', '1110'))\n",
    "print(len(MORSE_CODE_DICT))\n",
    "morse_code_numpy = {key:np.array([int(x) for x in MORSE_CODE_DICT[key].replace('.', '10').replace('-', '1110')] + [0, 0])\n",
    "                    for key in MORSE_CODE_DICT.keys()}\n",
    "for k in morse_code_numpy.keys():\n",
    "    #if len(morse_code_numpy[k]) == 12:\n",
    "    #    print(morse_code_numpy[k], k)\n",
    "    print(morse_code_numpy[k], k)\n",
    "print(len(morse_code_numpy))\n",
    "subset = list(morse_code_numpy.keys())\n",
    "#subset = ['3', '7', 'Y', 'Q', 'J',\n",
    "#          'M', 'R', 'U', 'H', 'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T18:44:56.737830Z",
     "start_time": "2021-05-04T18:44:55.497500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42)\n",
      "[tensor([1., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0.], device='cuda:0'), tensor([1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0.], device='cuda:0'), tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
      "        0., 0.], device='cuda:0'), tensor([1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
      "       device='cuda:0'), tensor([1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 0., 0.], device='cuda:0')] tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42])\n"
     ]
    }
   ],
   "source": [
    "id2key = subset\n",
    "key2id = {}\n",
    "for idx, s in enumerate(subset):\n",
    "    key2id[s] = idx\n",
    "\n",
    "X = [ttype(morse_code_numpy[k])for k in subset]\n",
    "Y = torch.LongTensor(np.arange(0,len(X)))\n",
    "print(Y.max())\n",
    "print(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T18:44:56.749737Z",
     "start_time": "2021-05-04T18:44:56.739072Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=padding, dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
    "        super(TCN, self).__init__()\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.linear.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.tcn(x)\n",
    "        return self.linear(y1[:, :, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T18:44:57.765195Z",
     "start_time": "2021-05-04T18:44:57.754067Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Weights: 86868\n",
      "TCN(\n",
      "  (tcn): TemporalConvNet(\n",
      "    (network): Sequential(\n",
      "      (0): TemporalBlock(\n",
      "        (conv1): Conv1d(1, 25, kernel_size=(45,), stride=(1,), padding=(44,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (conv2): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(44,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.0, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(1, 25, kernel_size=(45,), stride=(1,), padding=(44,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.0, inplace=False)\n",
      "          (4): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(44,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (downsample): Conv1d(1, 25, kernel_size=(1,), stride=(1,))\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "      (1): TemporalBlock(\n",
      "        (conv1): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(88,), dilation=(2,))\n",
      "        (chomp1): Chomp1d()\n",
      "        (relu1): ReLU()\n",
      "        (dropout1): Dropout(p=0.0, inplace=False)\n",
      "        (conv2): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(88,), dilation=(2,))\n",
      "        (chomp2): Chomp1d()\n",
      "        (relu2): ReLU()\n",
      "        (dropout2): Dropout(p=0.0, inplace=False)\n",
      "        (net): Sequential(\n",
      "          (0): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(88,), dilation=(2,))\n",
      "          (1): Chomp1d()\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.0, inplace=False)\n",
      "          (4): Conv1d(25, 25, kernel_size=(45,), stride=(1,), padding=(88,), dilation=(2,))\n",
      "          (5): Chomp1d()\n",
      "          (6): ReLU()\n",
      "          (7): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=25, out_features=43, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = TCN(1, 43, [25, 25], kernel_size=45, dropout=0.0).cuda()\n",
    "tot_weights = 0\n",
    "for p in model.parameters():\n",
    "    tot_weights += p.numel()\n",
    "print(\"Total Weights:\", tot_weights)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T18:45:03.212417Z",
     "start_time": "2021-05-04T18:44:58.374076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723cab73837d4a488b7f2b69d09f7804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "epochs = 5000\n",
    "Trainscale = 10\n",
    "device='cuda'\n",
    "batch_size = 8\n",
    "batches = int(np.ceil(43 / batch_size))\n",
    "\n",
    "progress_bar = tqdm(range(int(epochs)), bar_format='{l_bar}{bar:5}{r_bar}{bar:-5b}')\n",
    "times_100 = 0\n",
    "\n",
    "for epoch_idx in progress_bar:\n",
    "    perfs = []\n",
    "    losses = []\n",
    "    model.train()\n",
    "    for batch_idx in range(batches):\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0\n",
    "        permute = np.arange(0, 43)\n",
    "        for i in range(0, int(min(len(X) - (batch_idx*batch_size), \n",
    "                              batch_size))\n",
    "                       ):\n",
    "            iv = X[permute[batch_idx*batch_size + i]]\n",
    "            iv = iv.unsqueeze(0).unsqueeze(0).unsqueeze(-1)\n",
    "            iv = iv.repeat(1,1,1,Trainscale)\n",
    "            iv = iv.reshape(1,1,-1)\n",
    "            tv = Y[permute[batch_idx*batch_size + i]].to(device)\n",
    "            out = model(iv)\n",
    "            loss += loss_func(out,\n",
    "                         torch.cuda.LongTensor([tv]))\n",
    "            perfs.append((torch.argmax(out, dim=-1) == \n",
    "                          tv).sum().item())\n",
    "            \n",
    "        \n",
    "        loss = loss / min(len(X) - (batch_idx*batch_size), \n",
    "                          batch_size)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "            \n",
    "        #perfs = perfs[int(-loss_buffer_size/batch_size):]\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "        #losses = losses[int(-loss_buffer_size/batch_size):]\n",
    "\n",
    "\n",
    "        s = \"{}:{:2} Loss: {:.4f}, Perf: {:.4f}\"\n",
    "        format_list = [epoch_idx, batch_idx, np.mean(losses), \n",
    "                       np.sum(perfs)/((len(perfs)))]\n",
    "        s = s.format(*format_list)\n",
    "        progress_bar.set_description(s)\n",
    "    if (np.sum(perfs)/((len(perfs))) == 1.0) & (np.mean(losses) < .11):\n",
    "        times_100 += 1\n",
    "        if times_100 >= 3:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T17:29:25.641192Z",
     "start_time": "2021-05-04T17:29:24.894817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.023255813953488372\n",
      "2 0.023255813953488372\n",
      "5 0.023255813953488372\n",
      "6 0.023255813953488372\n",
      "7 0.023255813953488372\n",
      "8 0.046511627906976744\n",
      "9 0.11627906976744186\n",
      "10 1.0\n",
      "11 0.32558139534883723\n",
      "12 0.09302325581395349\n",
      "13 0.023255813953488372\n",
      "14 0.0\n",
      "15 0.023255813953488372\n",
      "16 0.023255813953488372\n",
      "17 0.023255813953488372\n",
      "18 0.046511627906976744\n",
      "19 0.023255813953488372\n",
      "20 0.0\n",
      "30 0.046511627906976744\n",
      "40 0.023255813953488372\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "evald = []\n",
    "evaldDict = {'test_perf':[],\n",
    "             'rate':[]}\n",
    "for nr in [1,2,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,30,40]:\n",
    "#for nr in range(1,20):\n",
    "    perfs = []\n",
    "    for batch_idx, iv in enumerate(X):\n",
    "        iv = iv.unsqueeze(0).unsqueeze(0).unsqueeze(-1)\n",
    "        iv = iv.repeat(1,1,1,nr)\n",
    "        iv = iv.reshape(1,1,-1)\n",
    "        tv = Y[batch_idx].to(device)\n",
    "        out = model(iv)\n",
    "        loss = loss_func(out,\n",
    "                         torch.cuda.LongTensor([tv]))\n",
    "\n",
    "\n",
    "        perfs.append((torch.argmax(out, dim=-1) == \n",
    "                      tv).sum().item())\n",
    "        #print(torch.argmax(out, dim=-1), \n",
    "        #              tv)\n",
    "    evaldDict['test_perf'].append(sum(perfs)/len(perfs))\n",
    "    evaldDict['rate'].append(nr)\n",
    "    print(nr, sum(perfs)/len(perfs))\n",
    "    evald.append({'scale':nr, \n",
    "                  'perf':sum(perfs)/len(perfs)})\n",
    "scale_perfs = pd.DataFrame(evald)\n",
    "scale_perfs.to_pickle(join(\"perf\", \"tcn_morse_test.dill\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
